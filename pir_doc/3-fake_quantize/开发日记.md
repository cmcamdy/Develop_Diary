
## TODO 
round_type记得check一下，默认值为1
- /home/cmcandy/code/PD/Paddle/paddle/fluid/operators/fake_quantize_op.cc
- /home/cmcandy/code/PD/Paddle/paddle/fluid/pir/dialect/operator/ir/ops.yaml
- /home/cmcandy/code/PD/Paddle/paddle/fluid/pir/dialect/operator/ir/ops_backward.yaml
- 



## 算子定义
paddle/fluid/operators/fake_quantize_op.h
```
在这个文件中，共有以下 9 个 kernel 定义(GPT)：
FakeQuantizeAbsMaxKernel
FakeQuantizeDequantizeAbsMaxKernel
FakeChannelWiseQuantizeAbsMaxKernel
FakeChannelWiseQuantizeDequantizeAbsMaxKernel
FakeQuantizeRangeAbsMaxKernel
FakeQuantizeMovingAverageAbsMaxKernel
FakeQuantizeDequantizeMovingAverageAbsMaxKernel
MovingAverageAbsMaxScaleKernel
StraightThroughEstimatorGradKernel
```

```
fake_quantize_abs_max
fake_channel_wise_quantize_abs_max
fake_quantize_range_abs_max
fake_quantize_moving_average_abs_max

# 这个应该是有的
quantize_linear? : /home/cmcandy/code/PD/Paddle/paddle/fluid/operators/quantize_linear_op.cc

moving_average_abs_max_scale
fake_quantize_dequantize_abs_max
fake_channel_wise_quantize_dequantize_abs_max
```

### FakeQuantizeAbsMaxKernel

- 注册代码
```cpp
REGISTER_OPERATOR(
    fake_quantize_abs_max,
    ops::FakeQuantOrWithDequantAbsMaxOp,
    ops::FakeQuantOrWithDequantAbsMaxOpMaker,
    paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
    paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>);
PD_REGISTER_STRUCT_KERNEL(fake_quantize_abs_max,
                          CPU,
                          ALL_LAYOUT,
                          ops::FakeQuantizeAbsMaxKernel,
                          float) {}

```

- fake_quantize_abs_max 是kernel_name
- ops::FakeQuantizeAbsMaxKernel 是meta_kernel_structure
- ops::FakeQuantOrWithDequantAbsMaxOp ,ops::FakeQuantOrWithDequantAbsMaxOpMaker是前向定义，前者有infershape，后者由参数定义
- 后面俩EmptyGradOpMaker其实等价于这个宏REGISTER_OP_WITHOUT_GRADIENT，说明这个算子没有梯度反传


#### 需要补充：
- paddle/fluid/pir/dialect/operator/ir/ops.yaml 中的映射看情况补充
- paddle/fluid/pir/dialect/operator/ir/ops.yaml 中的映射看情况补充
```yaml
- op: fake_quantize_abs_max
  args: (Tensor x, int bit_length = 8)
  output: Tensor(out), Tensor(out_scale)
  infer_meta:
    func: FakeQuantizeInferMeta
    param: [x]
  kernel:
    func: fake_quantize_abs_max
    data_type: x
```

- paddle/fluid/pir/dialect/operator/ir/ops_backward.yaml 中的映射看情况补充
- InferShape





### FakeChannelWiseQuantizeAbsMaxKernel


- 注册代码
```cpp
REGISTER_OPERATOR(
    fake_channel_wise_quantize_abs_max,
    ops::FakeChannelWiseQuantizeAbsMaxOp,
    ops::FakeChannelWiseQuantizeAbsMaxOpMaker,
    paddle::framework::EmptyGradOpMaker<paddle::framework::OpDesc>,
    paddle::framework::EmptyGradOpMaker<paddle::imperative::OpBase>);
PD_REGISTER_STRUCT_KERNEL(fake_channel_wise_quantize_abs_max,
                          CPU,
                          ALL_LAYOUT,
                          ops::FakeChannelWiseQuantizeAbsMaxKernel,
                          float) {}
```


## 测试
```
export FLAGS_PIR_OPTEST=true
export FLAGS_PIR_OPTEST_WHITE_LIST=true
export FLAGS_enable_pir_in_executor=true

time cmake .. -DCMAKE_CUDA_COMPILER=/usr/local/cuda-11.7/bin/nvcc -DPY_VERSION=3.8 -DWITH_GPU=ON -DON_INFER=ON -DWITH_NVCC_LAZY=ON -DWITH_TESTING=ON  -DCMAKE_EXE_LINKER_FLAGS="-Wl,--copy-dt-needed-entries" && make -j 8 && pip install -U /home/cmcandy/code/PD/Paddle/build/python/dist/paddlepaddle_gpu-0.0.0-cp38-cp38-linux_x86_64.whl
cd ..               
python test/legacy_test/test_fake_quantize_op.py 
```

## pre-commit
```
pre-commit run --files  \
        /home/cmcandy/code/PD/Paddle/paddle/fluid/pir/dialect/operator/utils/utils.cc          \
        /home/cmcandy/code/PD/Paddle/paddle/fluid/pir/dialect/operator/ir/ops.yaml              \
        /home/cmcandy/code/PD/Paddle/paddle/phi/infermeta/unary.h \
        /home/cmcandy/code/PD/Paddle/paddle/phi/infermeta/unary.cc  \
        /home/cmcandy/code/PD/Paddle/paddle/fluid/pir/dialect/op_generator/ops_api_gen.py
```
## add & commit 

```
git add /home/cmcandy/code/PD/Paddle/paddle/fluid/pir/dialect/operator/utils/utils.cc          \
        /home/cmcandy/code/PD/Paddle/paddle/fluid/pir/dialect/operator/ir/ops.yaml              \
        /home/cmcandy/code/PD/Paddle/paddle/phi/infermeta/unary.h \
        /home/cmcandy/code/PD/Paddle/paddle/phi/infermeta/unary.cc  \
        /home/cmcandy/code/PD/Paddle/paddle/fluid/pir/dialect/op_generator/ops_api_gen.py
git commit -m "[PIR] fix fake_quantize_abs_max & fake_channel_wise_quantize_abs_max & fake_quantize_range_abs_max & fake_quantize_moving_average_abs_max"
```


### bug 记录


- 暂时没思路
- 难道是要在map里面映射一下？
```
======================================================================
ERROR: test_fake_quantize_dequantize_moving_average_abs_max (__main__.TestFakeQuantizeMovingAverageAbsMaxOp)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "test/legacy_test/test_fake_quantize_op.py", line 358, in test_fake_quantize_dequantize_moving_average_abs_max
    self._fake_quantize_moving_average_abs_max(
  File "test/legacy_test/test_fake_quantize_op.py", line 340, in _fake_quantize_moving_average_abs_max
    self.check_grad(['X'], 'Out', user_defined_grads=gradient)
  File "/home/cmcandy/code/PD/Paddle/test/legacy_test/op_test.py", line 3001, in check_grad
    self.check_grad_with_place(
  File "/home/cmcandy/code/PD/Paddle/test/legacy_test/op_test.py", line 3303, in check_grad_with_place
    numeric_grads = self.check_grad_with_place_for_static(
  File "/home/cmcandy/code/PD/Paddle/test/legacy_test/op_test.py", line 3062, in check_grad_with_place_for_static
    analytic_grads = self._get_gradient(
  File "/home/cmcandy/code/PD/Paddle/test/legacy_test/op_test.py", line 3770, in _get_gradient
    self._check_ir_grad_output(
  File "/home/cmcandy/code/PD/Paddle/test/legacy_test/op_test.py", line 3599, in _check_ir_grad_output
    executor.run(
  File "/home/cmcandy/.local/lib/python3.8/site-packages/paddle/base/executor.py", line 1789, in run
    res = self._run_impl(
  File "/home/cmcandy/.local/lib/python3.8/site-packages/paddle/base/executor.py", line 1960, in _run_impl
    program, new_exe = self._executor_cache.get_program_and_executor(
  File "/home/cmcandy/.local/lib/python3.8/site-packages/paddle/base/executor.py", line 936, in get_program_and_executor
    return self._get_cached_program_and_executor(
  File "/home/cmcandy/.local/lib/python3.8/site-packages/paddle/base/executor.py", line 1083, in _get_program_and_executor
    "default": translate_to_pir(new_program.desc)
ValueError: (InvalidArgument) Input out not found when parsing op straight_through_estimator_grad
  [Hint: Expected legacy_input_vars.size() == 1UL, but received legacy_input_vars.size():0 != 1UL:1.] (at /home/cmcandy/code/PD/Paddle/paddle/fluid/ir_adaptor/translator/op_translator.cc:560)
```

- 感觉上应该是少了某一环
- build/paddle/fluid/pir/dialect/operator/ir/pd_op.h
```
RuntimeError: (PreconditionNotMet) op [pd_op.fake_quantize_abs_max] kernel output args defs should equal op outputs
  [Hint: Expected op_item->num_results() == output_defs.size(), but received op_item->num_results():2 != output_defs.size():0.] (at /home/cmcandy/code/PD/Paddle/paddle/fluid/pir/transforms/pd_op_to_kernel_pass.cc:2074)
```

- 这个是OPMaker的attr定义漏了。。。。
```
NotFoundError: (round_type) is not found in AttributeMap and RuntimeAttributeMap of (fake_quantize_abs_max) operator.
    [Hint: Expected iter != op_.RuntimeAttrs().end(), but received iter == op_.RuntimeAttrs().end().] (at /home/cmcandy/code/PD/Paddle/paddle/fluid/framework/operator.h:466)
    [operator < pd_kernel.legacy_kernel > error]
```


```
test/legacy_test/test_fake_quantize_op.py中的class TestFakeQuantizeRangeAbsMaxOp(OpTest):测试，会出现下面的问题
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /home/cmcandy/code/PD/Paddle/paddle/fluid/platform/device/gpu/gpu_info.cc:328)

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::framework::ThreadPoolTempl<paddle::framework::StlThreadEnvironment>::WorkerLoop(int)
1   paddle::framework::PirInterpreter::RunInstructionBaseAsync(unsigned long)
2   paddle::framework::PirInterpreter::RunInstructionBase(paddle::framework::InstructionBase*)
3   paddle::framework::LegacyKernelInstruction::Run()
4   paddle::framework::StructKernelImpl<paddle::operators::FakeQuantizeRangeAbsMaxKernel<phi::dtype::float16, phi::GPUContext>, void>::Compute(phi::KernelContext*)
5   paddle::operators::FakeQuantizeRangeAbsMaxKernel<phi::dtype::float16, phi::GPUContext>::Compute(paddle::framework::ExecutionContext const&) const
6   phi::DenseTensor::~DenseTensor()
7   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
8   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1711027220 (unix time) try "date -d @1711027220" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3e8000049f4) received by PID 18932 (TID 0x7f96015fe700) from PID 18932 ***]

```


```cpp
test/legacy_test/test_fake_quantize_op.py中的class TestFakeQuantizeMovingAverageAbsMaxOp(OpTest):测试，将with_gradient设为True会出现下面的问题
    def test_fake_quantize_dequantize_moving_average_abs_max(self):
        self._fake_quantize_moving_average_abs_max(
            np.float32,
            (8, 16, 7, 7),
            np.random.random,
            dequantize=True,
            # 开了with_gradient就会到
            # with_gradient=False,
            with_gradient=True,
        )

======================================================================
ERROR: test_fake_quantize_dequantize_moving_average_abs_max (__main__.TestFakeQuantizeMovingAverageAbsMaxOp)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "test/legacy_test/test_fake_quantize_op.py", line 358, in test_fake_quantize_dequantize_moving_average_abs_max
    self._fake_quantize_moving_average_abs_max(
  File "test/legacy_test/test_fake_quantize_op.py", line 340, in _fake_quantize_moving_average_abs_max
    self.check_grad(['X'], 'Out', user_defined_grads=gradient)
  File "/home/cmcandy/code/PD/Paddle/build/test/legacy_test/op_test.py", line 3001, in check_grad
    self.check_grad_with_place(
  File "/home/cmcandy/code/PD/Paddle/build/test/legacy_test/op_test.py", line 3303, in check_grad_with_place
    numeric_grads = self.check_grad_with_place_for_static(
  File "/home/cmcandy/code/PD/Paddle/build/test/legacy_test/op_test.py", line 3062, in check_grad_with_place_for_static
    analytic_grads = self._get_gradient(
  File "/home/cmcandy/code/PD/Paddle/build/test/legacy_test/op_test.py", line 3760, in _get_gradient
    executor.run(
  File "/home/cmcandy/.local/lib/python3.8/site-packages/paddle/base/executor.py", line 1789, in run
    res = self._run_impl(
  File "/home/cmcandy/.local/lib/python3.8/site-packages/paddle/base/executor.py", line 1960, in _run_impl
    program, new_exe = self._executor_cache.get_program_and_executor(
  File "/home/cmcandy/.local/lib/python3.8/site-packages/paddle/base/executor.py", line 936, in get_program_and_executor
    return self._get_cached_program_and_executor(
  File "/home/cmcandy/.local/lib/python3.8/site-packages/paddle/base/executor.py", line 1083, in _get_program_and_executor
    "default": translate_to_pir(new_program.desc)
RuntimeError: Error occurred at: /home/cmcandy/code/PD/Paddle/paddle/fluid/ir_adaptor/translator/op_translator.cc:287 :
Op straight_through_estimator_grad should have corresponding OpInfo pd_op.straight_through_estimator_grad

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::TranslateLegacyProgramToProgram(paddle::framework::ProgramDesc const&)
1   paddle::translator::ProgramTranslator::Translate()
2   paddle::translator::ProgramTranslator::TranslateBlock(paddle::framework::BlockDesc const&, unsigned long, unsigned long, paddle::translator::TranslationContext*, pir::Block*)
3   paddle::translator::ProgramTranslator::TranslateGeneralOperation(paddle::framework::OpDesc const*, paddle::translator::TranslationContext*, pir::Block*)
4   paddle::translator::OpTranscriber::operator()(pir::IrContext*, paddle::translator::TranslationContext*, paddle::framework::OpDesc const&, pir::Block*)
5   pir::IrNotMetException::IrNotMetException(std::string const&)
6   common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)


----------------------------------------------------------------------
Ran 11 tests in 5.138s

FAILED (errors=1)

```