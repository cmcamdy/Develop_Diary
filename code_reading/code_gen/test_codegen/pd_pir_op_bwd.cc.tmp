// This file is generated by "paddle/fluid/pir/dialect/op_generator/op_gen.py"
#include "/home/cmcandy/code/PD/Develop_Diary/code_reading/code_gen/test_codegen/pd_op.h"
#include "paddle/fluid/pir/dialect/kernel/ir/kernel_type.h"
#include "paddle/fluid/pir/dialect/operator/ir/ir_meta_tensor.h"
#include "paddle/fluid/pir/dialect/operator/ir/ir_selected_rows.h"
#include "paddle/fluid/pir/dialect/operator/ir/ir_tensor.h"
#include "paddle/fluid/pir/dialect/operator/ir/op_attribute.h"
#include "paddle/fluid/pir/dialect/operator/ir/op_type.h"
#include "paddle/fluid/primitive/rule/vjp/vjp.h"
#include "paddle/phi/api/lib/utils/allocator.h"
#include "paddle/phi/core/dense_tensor.h"
#include "paddle/phi/core/enforce.h"
#include "paddle/phi/infermeta/backward.h"
#include "paddle/phi/infermeta/binary.h"
#include "paddle/phi/infermeta/fusion.h"
#include "paddle/phi/infermeta/multiary.h"
#include "paddle/phi/infermeta/nullary.h"
#include "paddle/phi/infermeta/ternary.h"
#include "paddle/phi/infermeta/unary.h"
#include "paddle/pir/include/core/builtin_attribute.h"
#include "paddle/pir/include/core/builtin_op.h"
#include "paddle/pir/include/core/builtin_type.h"
#include "paddle/pir/include/core/ir_context.h"
#include "paddle/pir/include/core/op_base.h"

using namespace paddle::dialect;

namespace paddle {
namespace dialect {

void PartialSumGradOp::InferMeta( phi::InferMetaContext *infer_meta ) {
  auto fn = PD_INFER_META(phi::PartialSumGradInferMeta);
  fn(infer_meta);
}


std::vector<pir::Type> PartialSumGradOp::InferMeta(const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes) {
  PADDLE_ENFORCE_NOT_NULL(
        p_attributes, common::errors::Fatal("AttrtibueMap pointer in InferMeta function is nullptr."));
  auto& attributes = *p_attributes; (void)attributes;

  PADDLE_ENFORCE_EQ(input_values.size() == 2, true, phi::errors::InvalidArgument(
      "Num of inputs is expected to be 2 but got %d.", input_values.size()));

  pir::Value x_ = input_values[0]; (void)x_;
  VLOG(4) << "Builder construction outputs";
  bool is_from_tensor = false; (void) is_from_tensor;
  pir::VectorType x = x_.type().dyn_cast<pir::VectorType>(); (void)x;


  std::vector<paddle::dialect::IrTensor> vec_ir_tensor_x;
  for (size_t i=0; i < static_cast<size_t>(x.size()); i++) {
    if(x[i].isa<paddle::dialect::DenseTensorType>()) {
        auto x_type = x[i].dyn_cast<paddle::dialect::DenseTensorType>();
        vec_ir_tensor_x.push_back(paddle::dialect::IrTensor(paddle::dialect::TransToPhiDataType(x_type.dtype()),
                                                                    x_type.dims(),
                                                                    x_type.data_layout(),
                                                                    x_type.lod(),
                                                                    x_type.offset()));
    } else {
        PADDLE_THROW(phi::errors::Unimplemented("Only support DenseTensorType or AllocatedDenseTensorType"));
    }
  }
  std::vector<paddle::dialect::IrMetaTensor> vec_meta_x;
  for (size_t i=0; i < vec_ir_tensor_x.size(); i++) {
    vec_meta_x.push_back(paddle::dialect::IrMetaTensor(&vec_ir_tensor_x[i]));
  }

  std::vector<const phi::MetaTensor*> meta_x;
  for (size_t i=0; i < static_cast<size_t>(vec_meta_x.size()); i++) {
    meta_x.push_back(&vec_meta_x[i]);
  }
   std::vector<paddle::dialect::IrTensor> vec_dense_x_grad((x.size()), paddle::dialect::IrTensor());
  std::vector<paddle::dialect::IrMetaTensor> vec_meta_x_grad;
  for (size_t i=0; i < static_cast<size_t>(x.size()); i++) {
    vec_meta_x_grad.push_back(paddle::dialect::IrMetaTensor(&vec_dense_x_grad[i]));
  }
  std::vector<phi::MetaTensor*> meta_x_grad;
  for (size_t i=0; i < static_cast<size_t>(vec_meta_x_grad.size()); i++) {
    meta_x_grad.push_back(&vec_meta_x_grad[i]);
  }

  phi::PartialSumGradInferMeta(meta_x, meta_x_grad);

  std::vector<pir::Type> argument_outputs;
  std::vector<pir::Type> x_grad_types;
  for (size_t i=0; i < static_cast<size_t>(x.size()); i++) {
    x_grad_types.push_back(CvtToDenseTensorType(vec_dense_x_grad[i]));
  }
  pir::Type x_grad_type = pir::VectorType::get(pir::IrContext::Instance(), x_grad_types);

  argument_outputs.push_back(x_grad_type);

  return argument_outputs;
}

const char *PartialSumGradOp::attributes_name[2] = { "start_index", "length" };

OpInfoTuple PartialSumGradOp::GetOpInfo() {
  std::vector<paddle::dialect::OpInputInfo> inputs = { paddle::dialect::OpInputInfo("x", "pir::VectorType<paddle::dialect::DenseTensorType>", false, false, false, false), paddle::dialect::OpInputInfo("out_grad", "paddle::dialect::DenseTensorType", false, false, false, false) };
  std::vector<paddle::dialect::OpAttributeInfo> attributes = { paddle::dialect::OpAttributeInfo("start_index", "pir::Int32Attribute", ""), paddle::dialect::OpAttributeInfo("length", "pir::Int32Attribute", "") };
  std::vector<paddle::dialect::OpOutputInfo> outputs = { paddle::dialect::OpOutputInfo("x_grad", "pir::VectorType<paddle::dialect::DenseTensorType>", false, false) };
  paddle::dialect::OpRunTimeInfo run_time_info = paddle::dialect::OpRunTimeInfo("PartialSumGradInferMeta", {"x"}, "partial_sum_grad", {"x", "out_grad", "start_index", "length"}, {}, {}, {}, {});
  return std::make_tuple(inputs, attributes, outputs, run_time_info, "partial_sum_grad");
}

void PartialSumGradOp::Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int start_index, int length) {
  VLOG(4) << "Start build PartialSumGradOp";



  VLOG(4) << "Builder construction inputs";
  std::vector<pir::Value> argument_inputs = {x_, out_grad_};
  argument.AddInputs(argument_inputs);

  VLOG(4) << "Builder construction attributes";
  pir::AttributeMap argument_attributes = {};
  pir::Attribute attr_start_index = pir::Int32Attribute::get(pir::IrContext::Instance(), start_index);
  argument_attributes.insert({"start_index", attr_start_index});
  pir::Attribute attr_length = pir::Int32Attribute::get(pir::IrContext::Instance(), length);
  argument_attributes.insert({"length", attr_length});


  std::vector<pir::Type> argument_outputs = PartialSumGradOp::InferMeta(argument_inputs, &argument_attributes);
  argument.AddAttributes(argument_attributes);
  argument.AddOutputs(argument_outputs.begin(), argument_outputs.end());
  ::pir::PassStopGradientsDefaultly(argument);
}

void PartialSumGradOp::Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes) {
  VLOG(4) << "Start build PartialSumGradOp";


  PADDLE_ENFORCE_NE(
      attributes.find("start_index"),
      attributes.end(),
      phi::errors::InvalidArgument(
          "'start_index' Attribute is expected for PartialSumGradOp. "));
  int start_index = attributes.at("start_index").dyn_cast<pir::Int32Attribute>().data();

  PADDLE_ENFORCE_NE(
      attributes.find("length"),
      attributes.end(),
      phi::errors::InvalidArgument(
          "'length' Attribute is expected for PartialSumGradOp. "));
  int length = attributes.at("length").dyn_cast<pir::Int32Attribute>().data();


  VLOG(4) << "Builder construction inputs";
  std::vector<pir::Value> argument_inputs = {x_, out_grad_};
  argument.AddInputs(argument_inputs);

  VLOG(4) << "Builder construction attributes";
  pir::AttributeMap argument_attributes = {};
  pir::Attribute attr_start_index = pir::Int32Attribute::get(pir::IrContext::Instance(), start_index);
  argument_attributes.insert({"start_index", attr_start_index});
  pir::Attribute attr_length = pir::Int32Attribute::get(pir::IrContext::Instance(), length);
  argument_attributes.insert({"length", attr_length});


  std::vector<pir::Type> argument_outputs = PartialSumGradOp::InferMeta(argument_inputs, &argument_attributes);
  argument.AddAttributes(argument_attributes);
  argument.AddOutputs(argument_outputs.begin(), argument_outputs.end());
  ::pir::PassStopGradientsDefaultly(argument);
}

void PartialSumGradOp::VerifySig() {}

phi::DataType PartialSumGradOp::GetKernelTypeForVar(
    const std::string& var_name,
    const phi::DataType& tensor_dtype,
    const phi::DataType& expected_kernel_dtype) {
  VLOG(4) << "Get KernelType for Var of op: PartialSumGradOp";
  


  return expected_kernel_dtype;
}

const char *MovingAverageAbsMaxScaleGradOp::attributes_name[3] = { "bit_length", "round_type", "is_test" };

OpInfoTuple MovingAverageAbsMaxScaleGradOp::GetOpInfo() {
  std::vector<paddle::dialect::OpInputInfo> inputs = { paddle::dialect::OpInputInfo("out_grad", "paddle::dialect::DenseTensorType", false, false, false, false) };
  std::vector<paddle::dialect::OpAttributeInfo> attributes = { paddle::dialect::OpAttributeInfo("bit_length", "pir::Int32Attribute", ""), paddle::dialect::OpAttributeInfo("round_type", "pir::Int32Attribute", ""), paddle::dialect::OpAttributeInfo("is_test", "pir::BoolAttribute", "") };
  std::vector<paddle::dialect::OpOutputInfo> outputs = { paddle::dialect::OpOutputInfo("x_grad", "paddle::dialect::DenseTensorType", false, false) };
  paddle::dialect::OpRunTimeInfo run_time_info = paddle::dialect::OpRunTimeInfo("", {""}, "", {""}, {}, {}, {}, {});
  return std::make_tuple(inputs, attributes, outputs, run_time_info, "moving_average_abs_max_scale_grad");
}

void MovingAverageAbsMaxScaleGradOp::VerifySig() {}

phi::DataType MovingAverageAbsMaxScaleGradOp::GetKernelTypeForVar(
    const std::string& var_name,
    const phi::DataType& tensor_dtype,
    const phi::DataType& expected_kernel_dtype) {
  VLOG(4) << "Get KernelType for Var of op: MovingAverageAbsMaxScaleGradOp";
  


  return expected_kernel_dtype;
}

const char *FakeQuantizeDequantizeMovingAverageAbsMaxGradOp::attributes_name[4] = { "moving_rate", "bit_length", "round_type", "is_test" };

OpInfoTuple FakeQuantizeDequantizeMovingAverageAbsMaxGradOp::GetOpInfo() {
  std::vector<paddle::dialect::OpInputInfo> inputs = { paddle::dialect::OpInputInfo("out_grad", "paddle::dialect::DenseTensorType", false, false, false, false) };
  std::vector<paddle::dialect::OpAttributeInfo> attributes = { paddle::dialect::OpAttributeInfo("moving_rate", "pir::Int32Attribute", ""), paddle::dialect::OpAttributeInfo("bit_length", "pir::Int32Attribute", ""), paddle::dialect::OpAttributeInfo("round_type", "pir::Int32Attribute", ""), paddle::dialect::OpAttributeInfo("is_test", "pir::BoolAttribute", "") };
  std::vector<paddle::dialect::OpOutputInfo> outputs = { paddle::dialect::OpOutputInfo("x_grad", "paddle::dialect::DenseTensorType", false, false) };
  paddle::dialect::OpRunTimeInfo run_time_info = paddle::dialect::OpRunTimeInfo("", {""}, "", {""}, {}, {}, {}, {});
  return std::make_tuple(inputs, attributes, outputs, run_time_info, "fake_quantize_dequantize_moving_average_abs_max_grad");
}

void FakeQuantizeDequantizeMovingAverageAbsMaxGradOp::VerifySig() {}

phi::DataType FakeQuantizeDequantizeMovingAverageAbsMaxGradOp::GetKernelTypeForVar(
    const std::string& var_name,
    const phi::DataType& tensor_dtype,
    const phi::DataType& expected_kernel_dtype) {
  VLOG(4) << "Get KernelType for Var of op: FakeQuantizeDequantizeMovingAverageAbsMaxGradOp";
  


  return expected_kernel_dtype;
}

} // namespace dialect
} // namespace paddle


IR_DEFINE_EXPLICIT_TYPE_ID(paddle::dialect::PartialSumGradOp)

IR_DEFINE_EXPLICIT_TYPE_ID(paddle::dialect::MovingAverageAbsMaxScaleGradOp)

IR_DEFINE_EXPLICIT_TYPE_ID(paddle::dialect::FakeQuantizeDequantizeMovingAverageAbsMaxGradOp)

